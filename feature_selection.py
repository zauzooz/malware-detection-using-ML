import pandas as pd
import numpy as np
import time
import datetime
import json
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def obj_func(X, y, feature_list=None, w = 0.85):
    if feature_list is not None:
        features = np.where(feature_list>=0.4999)[0]
    
    fitness_val = 0

    if feature_list is not None:
        X = X[:, features]
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    lr = LinearRegression()
    lr.fit(X_train, y_train)

    accuracy = lr.score(X=X_test, y=y_test)

    # do something
    N = X.shape[1]
    fitness_val = w * accuracy + (1 - w) * (1 / N)

    return fitness_val

def MOGWO(X, y, lb=0, ub=1, objf=obj_func, no_search_agents=5, max_iter=10000):
    """
    Đầu vào:
        - X:
        - y:
        - objf:                 objective fucntion, trả về fitness value.
        - lb, ub:               phạm vi di chuyển.
        - n_dim:                chiều của vector, hay là số lượng features.
        - no_search_agents=5:   số lượng search agent.
        - max_iters=10000:      số vòng lặp tối đa.
    Đầu ra:
        - Vector là feature được chọn.
    """
    col_names = X.columns
    X = np.array(X)
    y = np.array(y)
    
    n_dim = X.shape[1]
    
    grid = None
    archive = None

    x_alpha = np.zeros(n_dim)
    alpha_score = float('inf')

    x_beta = np.zeros(n_dim)
    beta_score = float('inf')

    x_delta = np.zeros(n_dim)
    delta_score = float('inf')

    lb = [lb] * n_dim
    ub = [ub] * n_dim

    seach_agent_position = np.zeros((no_search_agents, n_dim))
    for i in range(n_dim):
        seach_agent_position[:, i] = (
            np.random.uniform(0, 1, no_search_agents) * (ub[i] - lb[i]) + lb[i]
        )

    for l in range(max_iter):
        # calculate fitness of each agent
        for i in range(no_search_agents):

            seach_agent_position[i] = np.clip(seach_agent_position[i], lb[0], ub[0])
            
            fitness = objf(X=X, y=y, feature_list=seach_agent_position[i])

            # update Alpha, Beta and Delta based on fitness

            if fitness < alpha_score:
                delta_score = beta_score
                x_delta = x_beta.copy()

                beta_score = alpha_score
                x_beta = x_alpha.copy()

                alpha_score = fitness
                x_alpha = seach_agent_position[i,:].copy()
            
            if fitness > alpha_score and fitness < beta_score:
                delta_score = beta_score
                x_delta = x_beta.copy()

                beta_score = fitness
                x_beta = seach_agent_position[i,:].copy()

            if fitness > alpha_score and fitness > beta_score and fitness < delta_score:
                delta_score = fitness
                x_delta = seach_agent_position[i,:]

        a = np.full((n_dim,), 2 - l * ((2) / max_iter))
        # update seach agent position
        for i in range(no_search_agents):
            r1 = np.random.randint(0, 2, n_dim)
            r2 = np.random.randint(0, 2, n_dim)
            A1 = 2 * a * r1 - a
            C1 = 2 * r2
            D_alpha = np.abs(C1 * x_alpha - seach_agent_position[i])
            X1 = x_alpha - A1 * D_alpha

            r1 = np.random.randint(0, 2, n_dim)
            r2 = np.random.randint(0, 2, n_dim)
            A2 = 2 * a * r1 - a
            C2 = 2 * r2
            D_beta = np.abs(C1 * x_beta - seach_agent_position[i])
            X2 = x_beta - A2 * D_beta

            r1 = np.random.randint(0, 2, n_dim)
            r2 = np.random.randint(0, 2, n_dim)
            A3 = 2 * a * r1 - a
            C3 = 2 * r2
            D_delta = np.abs(C1 * x_delta - seach_agent_position[i])
            X3 = x_delta - A3 * D_delta
            
            seach_agent_position[i] = (X1 + X2 + X3) / 3

    x_alpha = np.where(x_alpha > 0.49999, 1, 0)
    return (x_alpha, alpha_score)

def BCS(X, y, objf=obj_func,lb=0, ub=1, pa=0.25, n_nest=50, alpha=1, max_generations=10000):
    """
    Đầu vào:
        - X: dữ liệu đầu vào.
        - y: nhãn.
        - objf: hàm mục tiêu.
        - n_nest: top 50 cái tổ chim.

    Đầu ra:
        - Danh sách 
    """
    def get_new_nest(n):
        new_nest = np.random.uniform(0, 1, size=n)

        # đảm bảo có một đặc trưng trong danh sách các đặc trưng cần chọn
        while len(np.where(new_nest>=0.5)[0]) == 0:
            new_nest = np.random.uniform(0, 1, size=n)
        
        return new_nest
    
    def update_by_levy(x, n_dim, sigma = 2, alpha=alpha):
        # Generate a random step from the Levy distribution
        t = 1.0 / (np.sqrt(len(x)) * np.power(np.abs(np.random.normal()), 1.0 / sigma))
        step = alpha * np.random.normal() * t
        
        # Update the solution by adding the random step
        x_new = x + step
        
        return x_new

    col_names = X.columns
    X = np.array(X)
    y = np.array(y)

    n_dim = X.shape[1]
    n_samples = X.shape[0]
    nest = np.zeros((n_nest, n_dim))

    # init nest
    lb = [lb] * n_dim
    ub = [ub] * n_dim
    for i in range(n_dim):
        nest[:, i] = (np.random.uniform(0, 1, n_nest) * (ub[i] - lb[i]) + lb[i])

    fitness = np.zeros(n_nest)
    fitness.fill(-1 * float("inf"))

    global_fitness = -1 * float("inf")
    best_current_fitness = -1 * float("inf")
    best_nest = None

    for l in range(max_generations):
        for i in range(n_nest):
            # fitness[i] = np.clip(fitness[i], lb[0], ub[0])
            acc = objf(X=X, y=y, feature_list=nest[i])
            if acc > fitness[i]:
                fitness[i] = acc
            
            max_fitness = np.max(fitness)
            if max_fitness > global_fitness:
                global_fitness = max_fitness
            
            # tìm cái tổ lỏd nhất và thay thế nó bằng một cái tổ mới nào đó.
            index_min_fitness = np.argmin(fitness)
            nest[index_min_fitness] = get_new_nest(n_dim)
            
            # nếu như trong nest hiện tại, có nest lớn hơn nest lớn nhất đã tìm được, thay thế nó
            index_best_nest = np.argmax(fitness)
            if fitness[index_min_fitness] > best_current_fitness:
                best_nest = nest[index_best_nest]
                best_current_fitness = fitness[index_min_fitness]

            # cập nhật nest này bằng Lévy
            nest[i] = update_by_levy(x=nest[i], n_dim=n_dim)
    best_nest = np.where(best_nest>0.4999, 1, 0)
    return (best_nest, best_current_fitness)

def fetureSelection(X, y, max_iter=5):
    _start_time = time.time()
    X = X.dropna()
    X = X.loc[:, (X!=0).any(axis=0)]

    # thời gian bắt dầu thực thi mogwo.
    start_time = time.time() 
    (SF1, score_1) = MOGWO(X=X, y=y, max_iter=max_iter)
    # thời gian mà mogwo hoàn thành tác vụ của nó.
    mogwo_time = time.time() - start_time
    feature_mogwo = np.where(SF1>0)[0]


    # thời gian bắt đầu thực thi bcs
    start_time = time.time()
    (SF2, score_2) = BCS(X=X, y=y, n_nest=10, max_generations=max_iter)
    # thời gian mà bcs hoàn thành tác vụ của nó.
    bsc_time = time.time() - start_time
    feature_bcs = np.where(SF2>0)[0]

    SF = np.where(SF1 * SF2 > 0)[0]
    feature_adapt = time.time() - _start_time
    X_ = X.iloc[:, SF]
    score_3 = obj_func(X_, y)

    data = {
        "max_iter": str(max_iter),
        "mogwo_feature_selection": {
            "selected_feature": str(list(feature_mogwo)),
            "n_selected_feature": len(feature_mogwo),
            "score": score_1,
            "exec_time": mogwo_time,
        },
        "bcs_feature_selection": {
            "selected_feature": str(list(feature_bcs)),
            "n_selected_feature": len(feature_bcs),
            "score": score_2,
            "exec_time": bsc_time,
        },
        "adaptive_feature_selection":{
            "selected_feature": str(list(SF)),
            "n_selected_feature": len(SF),
            "score": score_3,
            "exec_time": feature_adapt,
        }
    }
    
    now = datetime.datetime.now()
    file_path = f"log/feature_selection/data_{now.day}-{now.month}-{now.year}_{now.hour}-{now.minute}-{now.second}-{now.microsecond}.json"
    json.dump(
        data,
        open(file_path, "w"),
        indent=6
    )

    return X_

# if __name__ == "__main__":
#     n = 986
#     m = 10000
#     X = pd.DataFrame(np.random.randint(0, 2, size = (n, m)))
#     y = np.random.randint(0, 2, size=n)
#     fetureSelection(X=X, y=y, max_iter=5)